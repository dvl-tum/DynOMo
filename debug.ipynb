{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load('experiments/dynosplatam_davis/splatam_horsejump-high/splatam_horsejump-high_0_kNN_200_200_200_-1_32_False_0.5_20_20_5_0.001_True_True_True_True_True_2000_16_16_128_16_0.1_True_False_False_True_True_2_1_0_1_20_240_455_0.0_0.0_0_False_False_True_False_True_0.1_3_aniso_deb_l2_emb_r3/eval/debug.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['min_idx', 'gs_traj_2D', 'gs_traj_3D', 'gt_traj_2D', 'occluded', 'pred_visibility'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_visibility = a['pred_visibility']\n",
    "comparison_visibility = pred_visibility.mean(dim=0).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_traj_2D = a['gs_traj_2D']\n",
    "comparison = gs_traj_2D.mean(dim=0).unsqueeze(1)\n",
    "# comparison = a['gt_traj_2D'].unsqueeze(1)\n",
    "# comparison[:, :, :, 0] *= 455\n",
    "# comparison[:, :, :, 1] *= 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 1, 50, 2]) torch.Size([10, 25, 50, 2])\n",
      "torch.Size([25, 1, 50]) torch.Size([10, 25, 50])\n",
      "torch.Size([1, 25, 50])\n",
      "torch.Size([1, 25, 50, 2])\n"
     ]
    }
   ],
   "source": [
    "print(comparison.shape, gs_traj_2D.shape)\n",
    "print(comparison_visibility.shape, pred_visibility.shape)\n",
    "print(pred_visibility.mean(dim=0).unsqueeze(0).shape)\n",
    "print(gs_traj_2D.mean(dim=0).unsqueeze(0).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_traj_2D_perm = gs_traj_2D.permute(1, 0, 2, 3)\n",
    "pred_visibility_perm = pred_visibility.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 10]) torch.Size([25, 50, 10, 1]) torch.Size([25, 50, 10])\n",
      "torch.Size([10, 25, 50, 2])\n",
      "tensor([[ 57.6701, 116.8360],\n",
      "        [ 76.1047, 137.1631],\n",
      "        [ 92.4431, 109.1113],\n",
      "        [182.2782,  91.2516],\n",
      "        [160.5210,  77.2249],\n",
      "        [100.1818, 104.8924],\n",
      "        [ 96.1117, 107.5409],\n",
      "        [ 99.4224, 114.4367],\n",
      "        [110.6395, 115.2574],\n",
      "        [103.9640, 108.2380],\n",
      "        [122.5278,  59.8487],\n",
      "        [127.0003,  56.6334],\n",
      "        [125.3885,  61.6155],\n",
      "        [117.5775,  59.8784],\n",
      "        [117.8646,  54.6548],\n",
      "        [  0.4416,   1.7195],\n",
      "        [126.9302, 110.4520],\n",
      "        [122.4352, 114.1768],\n",
      "        [116.5153, 123.3462],\n",
      "        [  0.4416,   1.7195],\n",
      "        [106.1834,  88.7647],\n",
      "        [128.4322, 108.0312],\n",
      "        [120.6127,  73.5627],\n",
      "        [122.6227,  62.1555],\n",
      "        [121.4648,  99.9884]])\n"
     ]
    }
   ],
   "source": [
    "dists = list()\n",
    "vis_dists = list()\n",
    "vars = list()\n",
    "for p in range(gs_traj_2D_perm.shape[0]):\n",
    "    d = torch.cdist(gs_traj_2D_perm[p].permute(1, 0, 2), comparison[p].permute(1, 0, 2))  \n",
    "    v = pred_visibility_perm[p].permute(1, 0) -  comparison_visibility[p].permute(1, 0)\n",
    "    dists.append(d)\n",
    "    vis_dists.append(v)\n",
    "    vars.append(torch.var(d, dim=0).squeeze())\n",
    "\n",
    "vars = torch.stack(vars)\n",
    "dists = torch.stack(dists)\n",
    "vis_dists = torch.stack(vis_dists)\n",
    "print(vars.shape,dists.shape, vis_dists.shape )\n",
    "print(a['gt_traj_2D'].shape)\n",
    "print(gs_traj_2D[a['min_idx'], torch.arange(gs_traj_2D.shape[1]), 0, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils.slam_external import build_rotation\n",
    "from datasets.gradslam_datasets.geometryutils import relative_transformation\n",
    "\n",
    "def evaluate_ate(gt_traj, est_traj):\n",
    "    \"\"\"\n",
    "    Input : \n",
    "        gt_traj: list of 4x4 matrices \n",
    "        est_traj: list of 4x4 matrices\n",
    "        len(gt_traj) == len(est_traj)\n",
    "    \"\"\"\n",
    "    gt_traj_pts = [gt_traj[idx][:3,3] for idx in range(len(gt_traj))]\n",
    "    est_traj_pts = [est_traj[idx][:3,3] for idx in range(len(est_traj))]\n",
    "\n",
    "    gt_traj_pts  = torch.stack(gt_traj_pts).detach().cpu().numpy().T\n",
    "    est_traj_pts = torch.stack(est_traj_pts).detach().cpu().numpy().T\n",
    "\n",
    "    _, _, trans_error = align(gt_traj_pts, est_traj_pts)\n",
    "\n",
    "    avg_trans_error = trans_error.mean()\n",
    "\n",
    "    return avg_trans_error\n",
    "\n",
    "\n",
    "def align(model, data):\n",
    "    \"\"\"Align two trajectories using the method of Horn (closed-form).\n",
    "\n",
    "    Args:\n",
    "        model -- first trajectory (3xn)\n",
    "        data -- second trajectory (3xn)\n",
    "\n",
    "    Returns:\n",
    "        rot -- rotation matrix (3x3)\n",
    "        trans -- translation vector (3x1)\n",
    "        trans_error -- translational error per point (1xn)\n",
    "\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    model_zerocentered = model - model.mean(1).reshape((3,-1))\n",
    "    data_zerocentered = data - data.mean(1).reshape((3,-1))\n",
    "\n",
    "    W = np.zeros((3, 3))\n",
    "    for column in range(model.shape[1]):\n",
    "        W += np.outer(model_zerocentered[:,\n",
    "                         column], data_zerocentered[:, column])\n",
    "    U, d, Vh = np.linalg.linalg.svd(W.transpose())\n",
    "    S = np.matrix(np.identity(3))\n",
    "    if (np.linalg.det(U) * np.linalg.det(Vh) < 0):\n",
    "        S[2, 2] = -1\n",
    "    rot = U*S*Vh\n",
    "    trans = data.mean(1).reshape((3,-1)) - rot * model.mean(1).reshape((3,-1))\n",
    "\n",
    "    model_aligned = rot * model + trans\n",
    "    alignment_error = model_aligned - data\n",
    "\n",
    "    trans_error = np.sqrt(np.sum(np.multiply(\n",
    "        alignment_error, alignment_error), 0)).A[0]\n",
    "\n",
    "    return rot, trans, trans_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_path = \"experiments/dynosplatam_iphone/splatam_paper-windmill/splatam_paper-windmill_0_kNN_200_200_200_20_20_5_0.001_False_False_True_True_True_16_16_128_16_0.1_True_2_0_20_0.5_0.5_False_False_False_0.1_3_aniso_deb_l2_emb_aligned_depth_anything_colmap_refined_segment_bug_rem_factor_False_bug_rem_hw_deb\"\n",
    "config_path = \"configs/iphone/dynosplatam_iphone.py\"\n",
    "\n",
    "params_path = \"experiments/dynosplatam_davis/splatam_scooter-black/splatam_scooter-black_0_kNN_200_200_200_-1_32_False_0.5_20_20_5_0.001_True_True_True_True_True_2000_16_16_128_16_0.1_True_False_False_True_True_2_1_0_1_20_240_455_0.0_0.0_0_False_False_True_False_True_0.1_3_aniso_deb_l2_emb_r3\"\n",
    "config_path = \"configs/davis/dynosplatam_davis.py\"\n",
    "\n",
    "params_path = \"experiments/dynosplatam_jono/splatam_boxes/ims/27_0_kNN_500_1000_0_-1_32_False_True_False_0.5_20_20_5_0.001_False_False_True_True_True_2000_16_16_128_16_0.1_True_False_False_True_True_2_1_0_1_20_360_640_0.0_0.0_transformed\"\n",
    "config_path = \"configs/jono_data/dynosplatam_jono_data_recent.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.get_data import load_scene_data\n",
    "import os\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from utils.eval_traj_restructured import TrajEvaluator\n",
    "import torch\n",
    "\n",
    "\n",
    "params, _, _,first_frame_w2c = load_scene_data(None, params_path, device=\"cuda:0\")\n",
    "\n",
    "seq_experiment = SourceFileLoader(\n",
    "        os.path.basename(config_path), config_path\n",
    "        # 'config.py', os.path.join(p, 'config.py')\n",
    "        ).load_module()\n",
    "dev = \"cuda:0\"\n",
    "\n",
    "evaluator = TrajEvaluator(\n",
    "    seq_experiment.config,\n",
    "    results_dir=params_path + '/eval',\n",
    "    vis_trajs=False, # seq_experiment.config['viz']['vis_tracked'])\n",
    "    best_x=1,\n",
    "    traj_len=0,\n",
    "    get_gauss_wise3D_track=True,\n",
    "    get_from3D=False,\n",
    "    vis_trajs_best_x=False,\n",
    "    stereo=False,\n",
    "    queries_first_t=True,\n",
    "    vis_thresh=0.5,\n",
    "    vis_thresh_start=0.5,\n",
    "    primary_device=dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvis_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DynoSplatTAM/utils/eval_traj_restructured.py:671\u001b[0m, in \u001b[0;36mvis_flow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m scene_flow \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((T\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw, \u001b[38;5;241m3\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev)\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 671\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    672\u001b[0m         \u001b[38;5;28mprint\u001b[39m(t, T\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    673\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev)\u001b[38;5;241m*\u001b[39mt\n",
      "File \u001b[0;32m~/Documents/DynoSplatTAM/utils/eval_traj_restructured.py:351\u001b[0m, in \u001b[0;36mTrajEvaluator.gauss_wise3D_track\u001b[0;34m(self, search_fg_only, start_pixels, start_time, start_3D, do_3D, only_t0)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m do_3D:\n\u001b[1;32m    349\u001b[0m     means2D_start\u001b[38;5;241m=\u001b[39m three2two(\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_matrix, means3D_start, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, do_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_norm_pix)\n\u001b[0;32m--> 351\u001b[0m     gauss_ids[start_time_best_x\u001b[38;5;241m==\u001b[39mtime] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_closest_to_start_pixels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeans2D_start\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_vis\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_pixels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     gauss_ids[start_time_best_x\u001b[38;5;241m==\u001b[39mtime] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_closest_to_start_pixels(\n\u001b[1;32m    357\u001b[0m         means3D_start\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[1;32m    358\u001b[0m         params_vis[:, time],\n\u001b[1;32m    359\u001b[0m         start_3D[start_time\u001b[38;5;241m==\u001b[39mtime])\n",
      "File \u001b[0;32m~/Documents/DynoSplatTAM/utils/eval_traj_restructured.py:569\u001b[0m, in \u001b[0;36mTrajEvaluator.find_closest_to_start_pixels\u001b[0;34m(self, means2D, params_vis, start_pixels, topk)\u001b[0m\n\u001b[1;32m    567\u001b[0m best_x_gauss_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_x):\n\u001b[0;32m--> 569\u001b[0m     gauss_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_closest_not_round\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeans2D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_vis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_closest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtopk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    575\u001b[0m     best_x_gauss_ids\u001b[38;5;241m.\u001b[39mappend(gauss_id)\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_x_gauss_ids[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluator.vis_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cam_traj(params):\n",
    "    gt_w2c_list = params['gt_w2c_all_frames']\n",
    "    num_frames = params['cam_unnorm_rots'].shape[-1]\n",
    "    latest_est_w2c = params['w2c']\n",
    "    latest_est_w2c_list = []\n",
    "    latest_est_w2c_list.append(latest_est_w2c)\n",
    "    valid_gt_w2c_list = []\n",
    "    valid_gt_w2c_list.append(gt_w2c_list[0])\n",
    "    for idx in range(1, num_frames):\n",
    "        # Check if gt pose is not nan for this time step\n",
    "        if torch.isnan(gt_w2c_list[idx]).sum() > 0:\n",
    "            continue\n",
    "        interm_cam_rot = torch.nn.functional.normalize(params['cam_unnorm_rots'][..., idx].detach())\n",
    "        interm_cam_trans = params['cam_trans'][..., idx].detach()\n",
    "        intermrel_w2c = torch.eye(4).cuda().float()\n",
    "        intermrel_w2c[:3, :3] = build_rotation(interm_cam_rot)\n",
    "        intermrel_w2c[:3, 3] = interm_cam_trans\n",
    "        latest_est_w2c = intermrel_w2c\n",
    "        latest_est_w2c_list.append(latest_est_w2c)\n",
    "        valid_gt_w2c_list.append(gt_w2c_list[idx])\n",
    "    gt_w2c_list = valid_gt_w2c_list\n",
    "    # Calculate ATE RMSE\n",
    "    ate_rmse = evaluate_ate(gt_w2c_list, latest_est_w2c_list)\n",
    "    print(\"Final Average ATE RMSE: {:.2f} cm\".format(ate_rmse*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Average ATE RMSE: 10.49 cm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "eval_cam_traj(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splatam_ugr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
